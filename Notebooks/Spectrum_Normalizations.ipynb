{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrum Continuum Normalization\n",
    "\n",
    "## Aim:\n",
    "   - To perform Chi^2 comparision between PHOENIX ACES spectra and my CRIRES observations.\n",
    "     \n",
    "## Problem:\n",
    "   - The nomalization of the observed spectra\n",
    "   - Differences in the continuum normalization affect the chi^2 comparison when using mixed models of two different spectra. \n",
    "   \n",
    "### Proposed Solution:\n",
    "  - equation (1) from [Passegger 2016](https://arxiv.org/pdf/1601.01877.pdf) \n",
    "          Fobs = F obs * (cont_fit model / cont_fit observation) where con_fit is a linear fit to the spectra.\n",
    "To take out and linear trends in the continuums and correct the amplitude of the continuum.\n",
    "   \n",
    "   \n",
    "In this notebook I outline what I do currently showing an example.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obeservatios were originally automatically continuum normalized in the iraf extraction pipeline. \n",
    "\n",
    "I believe the continuum is not quite at 1 here anymore due to the divsion by the telluric spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation\n",
    "obs = fits.getdata(\"/home/jneal/.handy_spectra/HD211847-1-mixavg-tellcorr_1.fits\")\n",
    "\n",
    "plt.plot(obs[\"wavelength\"], obs[\"flux\"])\n",
    "plt.hlines(1, 2111, 2124, linestyle=\"--\")\n",
    "plt.title(\"CRIRES spectra\")\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The two PHOENIX ACES spectra here are the first best guess of the two spectral components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "wav_model = fits.getdata(\"/home/jneal/Phd/data/PHOENIX-ALL/PHOENIX/WAVE_PHOENIX-ACES-AGSS-COND-2011.fits\")\n",
    "wav_model /= 10   # nm\n",
    "host = \"/home/jneal/Phd/data/PHOENIX-ALL/PHOENIX/Z-0.0/lte05700-4.50-0.0.PHOENIX-ACES-AGSS-COND-2011-HiRes.fits\"\n",
    "companion = \"/home/jneal/Phd/data/PHOENIX-ALL/PHOENIX/Z-0.0/lte02600-4.50-0.0.PHOENIX-ACES-AGSS-COND-2011-HiRes.fits\"\n",
    "\n",
    "host_f = fits.getdata(host)\n",
    "comp_f = fits.getdata(companion)\n",
    "plt.plot(wav_model, host_f, label=\"Host\")\n",
    "plt.plot(wav_model, comp_f, label=\"Companion\")\n",
    "plt.title(\"Phoenix spectra\")\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "mask = (2000 < wav_model) & (wav_model < 2200)\n",
    "wav_model = wav_model[mask] \n",
    "host_f = host_f[mask] \n",
    "comp_f = comp_f[mask] \n",
    "\n",
    "\n",
    "plt.plot(wav_model, host_f, label=\"Host\")\n",
    "plt.plot(wav_model, comp_f, label=\"Companion\")\n",
    "plt.title(\"Phoenix spectra\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Normalization\n",
    "I then continuum normalize the Phoenix spectrum locally around my observations \n",
    "by fitting an **exponenital** to the continuum like so.\n",
    "\n",
    "- Split the spectrum into 50 bins\n",
    "- Take median of 20 highest points in each bin.\n",
    "- Fix an exponetial\n",
    "- Evaulate at the orginal wavelength values\n",
    "- Divide original by the fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "def local_normalization(wave, flux, splits=50, method=\"exponential\", plot=False):\n",
    "    r\"\"\"Local minimization for section of Phoenix spectra.\n",
    "\n",
    "    Split spectra into many chunks and get the average of top 5\\% in each bin.\n",
    "\n",
    "    Fit to those points and normalize by that.\n",
    "    \"\"\"\n",
    "    org_flux = copy.copy(flux)\n",
    "    org_wave = copy.copy(wave)\n",
    "\n",
    "    while len(wave) % splits != 0:\n",
    "        # Shorten array untill can be evenly split up.\n",
    "        wave = wave[:-1]\n",
    "        flux = flux[:-1]\n",
    "\n",
    "    flux_split = np.split(flux, splits)\n",
    "    wav_split = np.split(wave, splits)\n",
    "\n",
    "    wav_points = np.empty(splits)\n",
    "    flux_points = np.empty(splits)\n",
    "\n",
    "    for i, (w, f) in enumerate(zip(wav_split, flux_split)):\n",
    "        wav_points[i] = np.median(w[np.argsort(f)[-20:]])  # Take the median of the wavelength values of max values.\n",
    "        flux_points[i] = np.median(f[np.argsort(f)[-20:]])\n",
    "\n",
    "    if method == \"scalar\":\n",
    "        norm_flux = np.median(flux_split) * np.ones_like(org_wave)\n",
    "    elif method == \"linear\":\n",
    "        z = np.polyfit(wav_points, flux_points, 1)\n",
    "        p = np.poly1d(z)\n",
    "        norm_flux = p(org_wave)\n",
    "    elif method == \"quadratic\":\n",
    "        z = np.polyfit(wav_points, flux_points, 2)\n",
    "        p = np.poly1d(z)\n",
    "        norm_flux = p(org_wave)\n",
    "    elif method == \"exponential\":\n",
    "        z = np.polyfit(wav_points, np.log(flux_points), deg=1, w=np.sqrt(flux_points))\n",
    "        p = np.poly1d(z)\n",
    "        norm_flux = np.exp(p(org_wave))   # Un-log the y values.\n",
    "\n",
    "    if plot:\n",
    "        plt.subplot(211)\n",
    "        plt.plot(wave, flux)\n",
    "        plt.plot(wav_points, flux_points, \"x-\", label=\"points\")\n",
    "        plt.plot(org_wave, norm_flux, label='norm_flux')\n",
    "        plt.legend()\n",
    "        plt.subplot(212)\n",
    "        plt.plot(org_wave, org_flux / norm_flux)\n",
    "        plt.title(\"Normalization\")\n",
    "        plt.xlabel(\"Wavelength (nm)\")\n",
    "        plt.show()\n",
    "\n",
    "    return org_flux / norm_flux\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_cont = local_normalization(wav_model, host_f, splits=50, method=\"exponential\", plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_cont = local_normalization(wav_model, comp_f, splits=50, method=\"exponential\", plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above the top is the unnormalize spectra, with the median points in orangeand the green line the continuum fit. The bottom plot is the contiuum normalized result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wav_model, comp_cont, label=\"Companion\")\n",
    "plt.plot(wav_model, host_cont-0.3, label=\"Host\")\n",
    "plt.title(\"Continuum Normalized \")\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(wav_model[20:200], comp_cont[20:200], label=\"Companion\")\n",
    "plt.plot(wav_model[20:200], host_cont[20:200], label=\"Host\")\n",
    "plt.title(\"Continuum Normalized - close up\")\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "ax = plt.gca()\n",
    "ax.get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Spectra\n",
    "I then mix the models using a combination of the two spectra.\n",
    "In this case with NO RV shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix(h, c, alpha):\n",
    "    return (h + c * alpha) / (1 + alpha)\n",
    "\n",
    "mix1 = mix(host_cont, comp_cont, 0.01)   # 1% of the companion spectra  \n",
    "mix2 = mix(host_cont, comp_cont, 0.05)   # 5% of the companion spectra  \n",
    "\n",
    "# plt.plot(wav_model[20:100], comp_cont[20:100], label=\"comp\")\n",
    "plt.plot(wav_model[20:100], host_cont[20:100], label=\"host\")\n",
    "plt.plot(wav_model[20:100], mix1[20:100], label=\"mix 1%\")\n",
    "plt.plot(wav_model[20:100], mix2[20:100], label=\"mix 5%\")\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The companion is cooler there are many more deeper lines present in the spectra.\n",
    "Even a small contribution of the companion spectra reduce the continuum of the mixed spectra considerably.\n",
    "\n",
    "When I compare these mixed spectra to my observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (wav_model > np.min(obs[\"wavelength\"])) & (wav_model < np.max(obs[\"wavelength\"]))\n",
    "\n",
    "plt.plot(wav_model[mask], mix1[mask], label=\"mix 1%\")\n",
    "plt.plot(wav_model[mask], mix2[mask], label=\"mix 5%\")\n",
    "plt.plot(obs[\"wavelength\"], obs[\"flux\"], label=\"obs\")\n",
    "#plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(wav_model[mask], mix2[mask], label=\"mix 5%\")\n",
    "plt.plot(wav_model[mask], mix1[mask], label=\"mix 1%\")\n",
    "plt.plot(obs[\"wavelength\"], obs[\"flux\"], label=\"obs\")\n",
    "plt.xlabel(\"Wavelength (nm)\")\n",
    "plt.legend()\n",
    "plt.xlim([2112, 2117])\n",
    "plt.ylim([0.9, 1.1])\n",
    "plt.title(\"Zoomed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see here my observations are above the continuum most of the time.\n",
    "What I have noticed is this drastically affects the chisquared result as the mix model is the one with the least amount of alpha.\n",
    "\n",
    "I am thinking of renormalizing my observations by implementing equation (1) from [Passegger 2016](https://arxiv.org/pdf/1601.01877.pdf) *(Fundamental M-dwarf parameters from high-resolution spectra using PHOENIX ACES modesl)*\n",
    "\n",
    "            F_obs = F_obs * (continuum_fit model / continuum_fit observation)\n",
    "            \n",
    "They fit a linear function to the continuum of the observation and computed spectra to account for *\"slight differences in the continuum level and possible linear trends between the already noramlized spectra.\"* \n",
    "\n",
    "- One difference is that they say they normalize the **average** flux of the spectra to unity. Would this make a difference in this method.\n",
    "\n",
    "\n",
    "## Questions\n",
    "- Would this be the correct approach to take to solve this? \n",
    "- Should I renomalize the observations first as well?\n",
    "- Am I treating the cooler M-dwarf spectra correctly in this approach? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try the method:\n",
    "from scipy.interpolate import interp1d\n",
    "mix1_norm = local_normalization(wav_model, mix1, splits=50, method=\"linear\", plot=True)\n",
    "mix2_norm = local_normalization(wav_model, mix2, splits=50, method=\"linear\", plot=True)\n",
    "obs_norm = local_normalization(obs[\"wavelength\"], obs[\"flux\"], splits=20, method=\"linear\", plot=True)\n",
    "\n",
    "normalization1 = mix1 / mix1_norm\n",
    "normalization2 = mix2 / mix2_norm\n",
    "obs_renorm1 = obs_norm * interp1d(wav_model, normalization1)(obs[\"wavelength\"])\n",
    "obs_renorm2 = obs_norm * interp1d(wav_model, normalization2)(obs[\"wavelength\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(obs[\"wavelength\"], obs_renorm1)\n",
    "plt.plot(wav_model[mask], mix1[mask], label=\"mix 1%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(obs[\"wavelength\"], obs_renorm2)\n",
    "plt.plot(wav_model[mask], mix2[mask], label=\"mix 5%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
